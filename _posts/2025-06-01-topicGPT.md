---
title: TopicGPT
date: 2025-06-01 00:00:00 +0800 #时间， 最后为时区北京 +0800
categories: [论文] #上级文档，下级文档
tags: [主题模型, 大语言模型]     # TAG
---

# **TopicGPT: A Prompt-Based Framework for Topic Modeling**

## 基本信息

- **作者**: Chau Minh Pham, Alexander Hoyle, Simeng Sun, Philip Resnik, Mohit Iyyer
- **发表**: NAACL, 2024
- **链接**: [arXiv](https://arxiv.org/abs/2311.01449)
- **代码**: [GitHub](https://github.com/chtmp223/topicGPT)

## 概要

**目的**: 利用大语言模型发掘文本的主题

**问题**: 传统主题模型（LDA）将主题表示为词汇集合，不易理解；用户对主题结果控制有限

**实验结果**: 更加符合人类挑选主题标准；有可解释性和描述说明；高度适应性

## 方法


### 1. Topic Generation

输入提示词和数据给 LLM，生成一些主题，再移除低频和重复的主题。这一步的输出可以作为 topicGPT 的输入，以便生成细粒度的子主题

具体包括以下两步

1. 生成主题：输入一份文档/语料和示例主题，llm 将文档分配到示例主题或生成一些匹配文档的新主题。主题包括主题名和解释说明。

2. 精简主题：使用 sentence-transformer 识别主题对的余弦相似度，合并重复的主题对

### 2. Topic Assignment

将主题分配给给定文档，输出包含分配的主题标签、文档特定的主题描述、支持这一分配的文档引用

![](https://raw.githubusercontent.com/InTheFuture7/attachment/main/202506011122097.png)

## 数据

我们采用两个英文数据集进行评估：Wiki 和 Bills：
1. Wiki 数据集（Merity 等人，2018 年）包含 14,290 篇符合核心编辑标准的维基百科文章，该数据集附带 15 个高层级、45 个中层级及 279 个低层级的人工标注标签。  
2. Bills 数据集（Adler 与 Wilkerson 2018 年整理，Hoyle 等人 2022 年汇编）收录了美国第 110 至 114 届国会的 32,661 份法案摘要，包含 21 个高层级和 114 个低层级的人工标注标签。  

## 实验

分别从两个数据集中选择 1000、1100 份文档，基于这些文档来生成主题。

其他生成主题的方法：连续输入 xx 篇文档后，没有出现新主题后就停止生成

使用 GPT-4 生成主题，GPT-3.5-turbo 为文档分配主题

不需要约束每篇文档对应的主题数量，但是这篇论文约束每篇文档仅 1 个主题


评估主题对齐性（Purity、ARI、MI）、稳定性（Stability）
