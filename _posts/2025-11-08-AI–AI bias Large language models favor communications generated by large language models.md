---
title: 2025-11-08-AI–AI bias Large language models favor communications generated by large language models
date: 2025-11-08 08:00:00 +0800 
categories: [论文] 
tags: [大模型]
---

概述：通过评估方（若干开闭源大模型和人类）对生成方的内容进行选择，观察到大模型相较于人类对大模型生成内容的选择概率更高，以此来揭示大模型的偏见。


问题：当大模型以更高概率选择大模型生成的结果，是否这就是偏见？是否只是大模型对高质量内容的选择？

论文引言中提到，在评估方中增加人类以作为基线，如果人类和大模型选择大模型生成内容概率相近，表明内容存在质量上的差异。如果大模型选择大模型生成内容更高，而人类选择概率更低，表明存在偏见。如果人类选择概率更高，可能是因为模型训练或评估时更加偏好人类风格的内容

> 详见：To address this, we solicit blind preference-judgments from human research assistants and ascribe bias to LLMs only where LLMs prefer LLM-presented objects more frequently than do humans.
> 翻译： 为了解决这个问题（即LLM与人类在撰写文本方面的技能差异可能是一个混淆因素），我们向人类研究助理征求了盲测偏好判断，并且只有当LLM比人类更频繁地偏爱LLM呈现的选项时，我们才将这种偏好归因于LLM的偏见。