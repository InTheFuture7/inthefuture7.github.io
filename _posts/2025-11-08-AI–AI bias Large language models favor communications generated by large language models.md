---
title: AI–AI bias Large language models favor communications generated by large language models
date: 2025-11-08 08:00:00 +0800
categories:
  - 论文
tags:
  - 大语言模型
  - 偏见
publish: true
---
期刊：PANS

发表时间：July 29, 2025

概述：通过评估方（若干开闭源大模型和人类）对生成方的内容进行选择，观察到大模型比人类有更高概率选择大模型生成内容，以此来揭示大模型的偏见。



问题：当大模型以更高概率选择大模型生成的结果，是否这就是偏见？是否只是大模型更倾向于选择高质量的内容？

思考：论文引言中提到，在评估方中增加人类专家，以专家的评估结果作为生成内容质量的ground truth。具体来说，
1. 如果人类和大模型都倾向于选择大模型生成内容，表明大模型生成内容的质量显著优于人类生成的。
2. 如果大模型选择大模型生成内容的概率更高，而人类选择的概率更低，表明大模型对大模型生成内容存在偏好，也就是大模型存在偏见。
3. 如果人类选择大模型生成内容的概率更高，则可能是因为模型训练或评估时更加偏好人类风格的内容。

> 详见：To address this, we solicit blind preference-judgments from human research assistants and ascribe bias to LLMs only where LLMs prefer LLM-presented objects more frequently than do humans.
> 翻译： 为了解决这个问题（即LLM与人类在撰写文本方面的技能差异可能是一个混淆因素），我们向人类研究助理征求了盲测偏好判断，并且**只有当LLM比人类更频繁地偏爱LLM呈现的选项时，我们才将这种偏好归因于LLM的偏见**。